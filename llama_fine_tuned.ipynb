{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:30:00.987372Z",
     "start_time": "2025-06-17T17:29:55.032704Z"
    }
   },
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling,BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftConfig,PeftModel\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\virt\\dla_reforgiato\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:30:00.993889Z",
     "start_time": "2025-06-17T17:30:00.989883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "DATA_PATH = \"data/spam_or_not_spam.csv\"\n",
    "MAX_LENGTH = 512\n",
    "OUTPUT_DIR = \"./llama3-1b-binary-classifier\"\n",
    "PRE_TRAINED = True\n",
    "# Set your Hugging Face token here\n",
    "hf_token = \"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\""
   ],
   "id": "cb7f35b7383eaaa0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:30:01.238495Z",
     "start_time": "2025-06-17T17:30:01.172004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"data/spam_or_not_spam.csv\").dropna(subset=[\"email\", \"label\"])\n",
    "df = df.dropna(subset=['email', 'label'])\n",
    "\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=1)\n",
    "\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=1)\n",
    "\n",
    "train = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "test = Dataset.from_pandas(test_df.reset_index(drop=True))"
   ],
   "id": "817d375622ad1917",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:30:01.251415Z",
     "start_time": "2025-06-17T17:30:01.247982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not PRE_TRAINED:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True,token = hf_token )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "        token = hf_token\n",
    "    )\n",
    "    peft_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ],
   "id": "26212a2e20fb2d85",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:30:06.609715Z",
     "start_time": "2025-06-17T17:30:01.259922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if PRE_TRAINED:\n",
    "    peft_config = PeftConfig.from_pretrained(\"spam_llama_model\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(peft_config.base_model_name_or_path,device_map=\"auto\")\n",
    "    model = PeftModel.from_pretrained(model,\"spam_llama_model\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"spam_llama_tokenizer\",use_fast=True)"
   ],
   "id": "7e66bd32c867a134",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:30:06.637083Z",
     "start_time": "2025-06-17T17:30:06.633602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"email\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)"
   ],
   "id": "3c228db3b21ceebf",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:30:09.391886Z",
     "start_time": "2025-06-17T17:30:06.660725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = train.map(tokenize, remove_columns=train.column_names)\n",
    "val = val.map(tokenize)\n",
    "test = test.map(tokenize)"
   ],
   "id": "122db9ca800377e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1919/1919 [00:01<00:00, 1202.36 examples/s]\n",
      "Map: 100%|██████████| 480/480 [00:00<00:00, 1241.19 examples/s]\n",
      "Map: 100%|██████████| 600/600 [00:00<00:00, 1408.29 examples/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:30:09.415833Z",
     "start_time": "2025-06-17T17:30:09.412328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not PRE_TRAINED:\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=1e-5,\n",
    "        logging_steps=10,\n",
    "        bf16=True,\n",
    "        save_total_limit=2,\n",
    "        optim=\"paged_adamw_8bit\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train,\n",
    "        eval_dataset=val,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ],
   "id": "1757d5ba63a5a152",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:31:14.968435Z",
     "start_time": "2025-06-17T17:30:09.436311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "predictions, references = [], []\n",
    "\n",
    "for example in val:\n",
    "    input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(\"cuda\")\n",
    "    attention_mask = torch.tensor(example[\"attention_mask\"]).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=2,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "    pred = 1 if \"1\" in decoded[-3:] else 0\n",
    "    true = int(example[\"label\"])\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(true)\n",
    "\n",
    "print(\"== Classification Report on Validation Set ==\")\n",
    "print(classification_report(references, predictions, digits=4))"
   ],
   "id": "5396ffabe5f97c15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification Report on Validation Set ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8351    1.0000    0.9101       400\n",
      "           1     1.0000    0.0125    0.0247        80\n",
      "\n",
      "    accuracy                         0.8354       480\n",
      "   macro avg     0.9175    0.5062    0.4674       480\n",
      "weighted avg     0.8626    0.8354    0.7626       480\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:32:34.351953Z",
     "start_time": "2025-06-17T17:31:15.074542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "predictions, references = [], []\n",
    "\n",
    "for example in test:\n",
    "    input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(\"cuda\")\n",
    "    attention_mask = torch.tensor(example[\"attention_mask\"]).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=2,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "    pred = 1 if \"1\" in decoded[-3:] else 0\n",
    "    true = int(example[\"label\"])\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(true)\n",
    "\n",
    "print(\"== Classification Report on Test Set ==\")\n",
    "print(classification_report(references, predictions, digits=4))"
   ],
   "id": "760497e7519a4fef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification Report on Test Set ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8202    0.9919    0.8979       492\n",
      "           1     0.2000    0.0093    0.0177       108\n",
      "\n",
      "    accuracy                         0.8150       600\n",
      "   macro avg     0.5101    0.5006    0.4578       600\n",
      "weighted avg     0.7085    0.8150    0.7395       600\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
