{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:30:50.044003Z",
     "start_time": "2025-06-17T16:30:46.016175Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\virt\\dla_reforgiato\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM ,BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e7ace69f5260c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:30:50.050522Z",
     "start_time": "2025-06-17T16:30:50.046007Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "DATA_PATH = \"data/spam_or_not_spam.csv\"\n",
    "MAX_LENGTH = 512\n",
    "hf_token = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc13f04d0b9a756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:30:51.427302Z",
     "start_time": "2025-06-17T16:30:50.292239Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True,token = hf_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e26fef3b96b5f1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:30:51.440042Z",
     "start_time": "2025-06-17T16:30:51.435280Z"
    }
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # ✅ evita il warning\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b0725f16641754c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:31:01.786850Z",
     "start_time": "2025-06-17T16:30:51.449149Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.84s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    token = hf_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34394e5618cfd0d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:31:01.800532Z",
     "start_time": "2025-06-17T16:31:01.796522Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_chat(example):\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'Classify this email as spam (1) or not spam (0): \"{example[\"email\"]}\"'\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": str(example[\"label\"])\n",
    "        }\n",
    "    ]\n",
    "    full_text = tokenizer.apply_chat_template(\n",
    "        conversation,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    return {\"text\": full_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ccd6bc0a8ee7a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:31:01.812136Z",
     "start_time": "2025-06-17T16:31:01.809136Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"email\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47f2eb18c56f6faa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:31:01.878174Z",
     "start_time": "2025-06-17T16:31:01.820831Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/spam_or_not_spam.csv\").dropna(subset=[\"email\", \"label\"])\n",
    "df = df.dropna(subset=['email', 'label'])\n",
    "\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=1)\n",
    "\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=1)\n",
    "\n",
    "train = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "test = Dataset.from_pandas(test_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1c0d2200cca1081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:31:02.761321Z",
     "start_time": "2025-06-17T16:31:01.891290Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 480/480 [00:00<00:00, 1149.57 examples/s]\n",
      "Map: 100%|██████████| 600/600 [00:00<00:00, 1590.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "val = val.map(tokenize)\n",
    "test = test.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf4ca3db7c5d48bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:32:31.969157Z",
     "start_time": "2025-06-17T16:31:02.773721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification Report on Validation Set ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8378    0.6975    0.7613       400\n",
      "           1     0.1769    0.3250    0.2291        80\n",
      "\n",
      "    accuracy                         0.6354       480\n",
      "   macro avg     0.5074    0.5112    0.4952       480\n",
      "weighted avg     0.7277    0.6354    0.6726       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions, references = [], []\n",
    "\n",
    "for example in val:\n",
    "    input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(\"cuda\")\n",
    "    attention_mask = torch.tensor(example[\"attention_mask\"]).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=2,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "    pred = 1 if \"1\" in decoded[-3:] else 0\n",
    "    true = int(example[\"label\"])\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(true)\n",
    "\n",
    "print(\"== Classification Report on Validation Set ==\")\n",
    "print(classification_report(references, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "770d28ee7609d40d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:34:23.266577Z",
     "start_time": "2025-06-17T16:32:32.060306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification Report on Test Set ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8042    0.6931    0.7445       492\n",
      "           1     0.1420    0.2315    0.1761       108\n",
      "\n",
      "    accuracy                         0.6100       600\n",
      "   macro avg     0.4731    0.4623    0.4603       600\n",
      "weighted avg     0.6850    0.6100    0.6422       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions, references = [], []\n",
    "\n",
    "for example in test:\n",
    "    input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(\"cuda\")\n",
    "    attention_mask = torch.tensor(example[\"attention_mask\"]).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=2,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "    pred = 1 if \"1\" in decoded[-3:] else 0\n",
    "    true = int(example[\"label\"])\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(true)\n",
    "\n",
    "print(\"== Classification Report on Test Set ==\")\n",
    "print(classification_report(references, predictions, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
