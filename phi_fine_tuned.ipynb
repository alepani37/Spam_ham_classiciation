{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:20:34.896638Z",
     "start_time": "2025-06-17T17:20:27.649871Z"
    }
   },
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling,BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftConfig,PeftModel\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\virt\\dla_reforgiato\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:20:34.905239Z",
     "start_time": "2025-06-17T17:20:34.901149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "DATA_PATH = \"data/spam_or_not_spam.csv\"\n",
    "MAX_LENGTH = 512\n",
    "OUTPUT_DIR = \"./phi-3-mini\"\n",
    "PRE_TRAINED = True\n",
    "# Set your Hugging Face token here\n",
    "hf_token = \"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\""
   ],
   "id": "cb7f35b7383eaaa0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:20:35.086788Z",
     "start_time": "2025-06-17T17:20:35.081967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ],
   "id": "521e5be6d3e47f87",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:20:35.149067Z",
     "start_time": "2025-06-17T17:20:35.089296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"data/spam_or_not_spam.csv\").dropna(subset=[\"email\", \"label\"])\n",
    "df = df.dropna(subset=['email', 'label'])\n",
    "\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=1)\n",
    "\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=1)\n",
    "\n",
    "train = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "test = Dataset.from_pandas(test_df.reset_index(drop=True))"
   ],
   "id": "817d375622ad1917",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:20:35.163189Z",
     "start_time": "2025-06-17T17:20:35.158580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not PRE_TRAINED:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True,token = hf_token )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.float16,\n",
    "        token = hf_token\n",
    "    )\n",
    "    peft_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ],
   "id": "26212a2e20fb2d85",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:20:42.234299Z",
     "start_time": "2025-06-17T17:20:35.171193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if PRE_TRAINED:\n",
    "    peft_config = PeftConfig.from_pretrained(\"spam_phi_model\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME,device_map=\"auto\",quantization_config=bnb_config)\n",
    "    model = PeftModel.from_pretrained(model,\"spam_phi_model\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"spam_phi_tokenizer\",use_fast=True)"
   ],
   "id": "7e66bd32c867a134",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.62s/it]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:20:42.250499Z",
     "start_time": "2025-06-17T17:20:42.247498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"email\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)"
   ],
   "id": "3c228db3b21ceebf",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:20:44.409239Z",
     "start_time": "2025-06-17T17:20:42.263661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = train.map(tokenize, remove_columns=train.column_names)\n",
    "val = val.map(tokenize)\n",
    "test = test.map(tokenize)"
   ],
   "id": "122db9ca800377e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1919/1919 [00:01<00:00, 1371.01 examples/s]\n",
      "Map: 100%|██████████| 480/480 [00:00<00:00, 1454.79 examples/s]\n",
      "Map: 100%|██████████| 600/600 [00:00<00:00, 1671.88 examples/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:20:44.424698Z",
     "start_time": "2025-06-17T17:20:44.421416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not PRE_TRAINED:\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=1e-5,\n",
    "        logging_steps=10,\n",
    "        bf16=True,\n",
    "        save_total_limit=2,\n",
    "        optim=\"paged_adamw_8bit\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train,\n",
    "        eval_dataset=val,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ],
   "id": "1757d5ba63a5a152",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:22:23.223490Z",
     "start_time": "2025-06-17T17:20:44.438607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "predictions, references = [], []\n",
    "\n",
    "for example in val:\n",
    "    input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(\"cuda\")\n",
    "    attention_mask = torch.tensor(example[\"attention_mask\"]).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=2,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "    pred = 1 if \"1\" in decoded[-3:] else 0\n",
    "    true = int(example[\"label\"])\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(true)\n",
    "\n",
    "print(\"== Classification Report on Validation Set ==\")\n",
    "print(classification_report(references, predictions, digits=4))"
   ],
   "id": "5396ffabe5f97c15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification Report on Validation Set ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7929    0.3350    0.4710       400\n",
      "           1     0.1447    0.5625    0.2302        80\n",
      "\n",
      "    accuracy                         0.3729       480\n",
      "   macro avg     0.4688    0.4487    0.3506       480\n",
      "weighted avg     0.6849    0.3729    0.4309       480\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T17:24:28.597364Z",
     "start_time": "2025-06-17T17:22:23.342143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "predictions, references = [], []\n",
    "\n",
    "for example in test:\n",
    "    input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(\"cuda\")\n",
    "    attention_mask = torch.tensor(example[\"attention_mask\"]).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=2,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "    pred = 1 if \"1\" in decoded[-3:] else 0\n",
    "    true = int(example[\"label\"])\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(true)\n",
    "\n",
    "print(\"== Classification Report on Test Set ==\")\n",
    "print(classification_report(references, predictions, digits=4))"
   ],
   "id": "760497e7519a4fef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Classification Report on Test Set ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7393    0.3171    0.4438       492\n",
      "           1     0.1362    0.4907    0.2133       108\n",
      "\n",
      "    accuracy                         0.3483       600\n",
      "   macro avg     0.4378    0.4039    0.3285       600\n",
      "weighted avg     0.6308    0.3483    0.4023       600\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
